{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate file with nearby cities\n",
    "Provide the min, max search range and the start city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import radians, cos, sin, sqrt, atan2\n",
    "\n",
    "# Parameters\n",
    "city = \"Groningen\"\n",
    "min_radius_km = 200\n",
    "max_radius_km = 800\n",
    "\n",
    "# Load the GeoNames data\n",
    "file_path = \"cities15000.txt\"  # Update with the actual file path\n",
    "columns = [\n",
    "    \"geonameid\", \"name\", \"asciiname\", \"alternatenames\", \"latitude\", \"longitude\", \n",
    "    \"feature class\", \"feature code\", \"country code\", \"cc2\", \"admin1 code\", \n",
    "    \"admin2 code\", \"admin3 code\", \"admin4 code\", \"population\", \"elevation\", \n",
    "    \"dem\", \"timezone\", \"modification date\"\n",
    "]\n",
    "\n",
    "# Load the file into a pandas DataFrame\n",
    "cities = pd.read_csv(file_path, sep='\\t', names=columns, low_memory=False)\n",
    "\n",
    "# Haversine function to calculate distance between two lat/lon pairs\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    return R * c\n",
    "\n",
    "# Function to find cities within a radius\n",
    "def find_cities_within_radius(lat, lon, min_radius_km, max_radius_km, min_population=0):\n",
    "    cities['distance_km'] = cities.apply(\n",
    "        lambda row: haversine(lat, lon, row['latitude'], row['longitude']), axis=1\n",
    "    )\n",
    "    nearby_cities = cities[(cities['distance_km'] <= max_radius_km) & (cities['distance_km'] >= min_radius_km) & (cities['population'] >= min_population)]\n",
    "    return nearby_cities[['name', 'latitude', 'longitude', 'population', 'distance_km', 'country code']]\n",
    "\n",
    "def get_coordinates_by_city_name(city_name, country_code=None):\n",
    "    \"\"\"\n",
    "    Returns the latitude and longitude of a city given its name.\n",
    "    \n",
    "    Parameters:\n",
    "    - city_name (str): The name of the city to search for.\n",
    "    - country_code (str): Optional. ISO 3166-1 alpha-2 country code to narrow down the search.\n",
    "    \n",
    "    Returns:\n",
    "    - (float, float): A tuple containing (latitude, longitude) if found.\n",
    "    - None: If the city is not found.\n",
    "    \"\"\"\n",
    "    # Filter DataFrame by city name (case insensitive)\n",
    "    filtered = cities[cities['name'].str.lower() == city_name.lower()]\n",
    "\n",
    "    # Optionally filter by country code\n",
    "    if country_code:\n",
    "        filtered = filtered[filtered['country code'].str.upper() == country_code.upper()]\n",
    "\n",
    "    if not filtered.empty:\n",
    "        # Get the first matching result\n",
    "        city_data = filtered.iloc[0]\n",
    "        return city_data['latitude'], city_data['longitude']\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "latitude, longitude = get_coordinates_by_city_name(city)  # Example coordinates for Paris\n",
    "nearby_cities = find_cities_within_radius(latitude, longitude, min_radius_km, max_radius_km, 100_000)\n",
    "\n",
    "# Display the result\n",
    "print(nearby_cities)\n",
    "# Save the nearby cities to a text file\n",
    "output_file_path = \"nearby_cities.csv\"\n",
    "nearby_cities.to_csv(output_file_path, sep='\\t', index=False)\n",
    "print(f\"Nearby cities saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filter the generated list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the nearby_cities.csv file\n",
    "nearby_cities_df = pd.read_csv('nearby_cities.csv', sep='\\t')\n",
    "\n",
    "# Filter the dataframe to keep only entries where country code is in the list\n",
    "filtered_countries = ['FR', 'DE', 'BE', 'DK','PL']\n",
    "filtered_df = nearby_cities_df[nearby_cities_df['country code'].isin(filtered_countries)]\n",
    "\n",
    "# Check the resulting dataframe\n",
    "print(filtered_df.head())\n",
    "print(f\"Size of filtered_df: {filtered_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException, TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "def fetch_hotel_prices_and_links(city, max_price=1000, group_adults=24, checkin=\"2025-03-07\", checkout=\"2025-03-09\", breakfast_included=False, save_file = False):\n",
    "    # or use your browser of choice\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    if breakfast_included:\n",
    "        driver.get(f\"https://www.booking.com/searchresults.en-gb.html?&ss={city}&ssne={city}&ssne_untouched={city}&lang=en-gb&sb=1&src_elem=sb&dest_type=city&checkin={checkin}&checkout={checkout}&group_adults={group_adults}&no_rooms=1&group_children=0&sr_view=list&order=price&nflt=mealplan%3D1\")\n",
    "    else:\n",
    "        driver.get(f\"https://www.booking.com/searchresults.en-gb.html?&ss={city}&ssne={city}&ssne_untouched={city}&lang=en-gb&sb=1&src_elem=sb&dest_type=city&checkin={checkin}&checkout={checkout}&group_adults={group_adults}&no_rooms=1&group_children=0&sr_view=list&order=price\")\n",
    "\n",
    "    prices = driver.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"price-and-discounted-price\"]')\n",
    "    hotels = []\n",
    "    prices = driver.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"price-and-discounted-price\"]')\n",
    "\n",
    "    if save_file:\n",
    "        with open(f\"./saved_pages/{city}.html\", \"w\", encoding='utf-8') as f:\n",
    "            f.write(driver.page_source)\n",
    "\n",
    "    for i in range(len(prices)):\n",
    "        retry_count = 3  # Retry a few times in case of a stale element\n",
    "        while retry_count > 0:\n",
    "            try:\n",
    "                prices = driver.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"price-and-discounted-price\"]')\n",
    "                price = prices[i]\n",
    "\n",
    "                price_text = price.text.replace(\"â‚¬\", \"\").replace(\",\", \"\").strip()\n",
    "                price_value = float(price_text)\n",
    "\n",
    "                if price_value < max_price:\n",
    "                    try:\n",
    "                        # 6 divs higher should always still be in the selected hotel's div\n",
    "                        parent_div = price.find_element(By.XPATH, './ancestor::div[6]')\n",
    "                        availability_button = parent_div.find_element(By.CSS_SELECTOR, 'a[data-testid=\"availability-cta-btn\"]')\n",
    "\n",
    "                        # If button is found, retrieve the link\n",
    "                        link = availability_button.get_attribute('href')\n",
    "                        hotels.append({\"price\": price_value, \"link\": link})\n",
    "\n",
    "                    except NoSuchElementException:\n",
    "                        # Handle cases where neither attempt finds the button\n",
    "                        print(\"Availability button not found for this listing.\")\n",
    "                        hotels.append({\"price\": price_value, \"link\": \"No link available\"})\n",
    "\n",
    "                break  # Break out of the retry loop if successful\n",
    "            except StaleElementReferenceException:\n",
    "                retry_count -= 1\n",
    "                if retry_count == 0:\n",
    "                    print(f\"Failed to process price due to stale element: {i}\")\n",
    "            except TimeoutException:\n",
    "                retry_count -= 1\n",
    "                if retry_count == 0:\n",
    "                    print(\"Availability button did not appear in time.\")\n",
    "                    hotels.append({\"price\": price_value, \"link\": \"No link available\"})\n",
    "\n",
    "    driver.quit()\n",
    "    return hotels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multithreaded search\n",
    "Be careful when using this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Parameters\n",
    "max_price = 1300\n",
    "breakfast_included = True\n",
    "checkin = \"2025-03-07\"   # Format: YYYY-MM-DD\n",
    "checkout = \"2025-03-09\"    # Format: YYYY-MM-DD\n",
    "people_count = 24\n",
    "\n",
    "# Wrapper function for fetching data\n",
    "def fetch_and_save(city_list, max_price=1000, group_adults=24, checkin=\"2025-03-07\", checkout=\"2025-03-09\", breakfast_included=False, save_file = False):\n",
    "    # Ensure the output file exists and has the correct headers\n",
    "    save_file_path = 'hotels.csv'\n",
    "    if breakfast_included:\n",
    "        save_file_path = 'hotels_breakfast.csv'\n",
    "    \n",
    "    if not os.path.exists(save_file_path):\n",
    "        with open(save_file_path, 'w') as file:\n",
    "            file.write(\"City\\tPrice\\tLink\\n\")\n",
    "\n",
    "    def worker(city):\n",
    "        # Fetch hotel prices and links for a single city\n",
    "        print(f\"Fetching data for {city}...\")\n",
    "        return {city: fetch_hotel_prices_and_links(city, max_price, group_adults, checkin, checkout, breakfast_included, save_file)}\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Submit all city requests\n",
    "        future_to_city = {executor.submit(worker, city): city for city in city_list}\n",
    "\n",
    "        # Process results as they complete\n",
    "        for future in as_completed(future_to_city):\n",
    "            city = future_to_city[future]\n",
    "            try:\n",
    "                data = future.result()  # Get the result\n",
    "                hotels = data[city]\n",
    "\n",
    "                # Append results to the file\n",
    "                with open(save_file_path, 'a', encoding='utf-8') as file:\n",
    "                    for hotel in hotels:\n",
    "                        file.write(f\"{city}\\t{hotel['price']}\\t{hotel['link']}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching data for {city}: {e}\")\n",
    "\n",
    "city_list = filtered_df['name']\n",
    "\n",
    "print(\"Starting parallel hotel data fetching...\")\n",
    "fetch_and_save(city_list, max_price=max_price, group_adults=people_count, checkin=checkin, checkout=checkout, breakfast_included=breakfast_included)\n",
    "\n",
    "save_file_path = 'hotels.csv'\n",
    "if breakfast_included:\n",
    "    save_file_path = 'hotels_breakfast.csv'\n",
    "    \n",
    "print(f\"Data fetching complete. Check '{save_file_path}' for results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Single thread search\n",
    "Is slow, but will go undetected for longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Parameters\n",
    "max_price = 1000\n",
    "breakfast_included = False\n",
    "checkin = \"2025-03-07\"   # Format: YYYY-MM-DD\n",
    "checkout = \"2025-03-09\"    # Format: YYYY-MM-DD\n",
    "people_count = 24\n",
    "\n",
    "\n",
    "if not os.path.exists('hotels.csv'):\n",
    "    with open('hotels.csv', 'w') as file:\n",
    "        file.write(\"City\\tPrice\\tLink\\n\")\n",
    "        \n",
    "for city in filtered_df['name']:\n",
    "    print(f\"Fetching prices for {city}\")\n",
    "    hotels = fetch_hotel_prices_and_links(city, max_price=max_price, group_adults=people_count, checkin=checkin, checkout=checkout, breakfast_included=breakfast_included)\n",
    "    with open('hotels.csv', 'a', encoding='utf-8') as file:\n",
    "        for hotel in hotels:\n",
    "            file.write(f\"{city}\\t{hotel['price']}\\t{hotel['link']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create list of unique cities\n",
    "This can be loaded in [Google Maps](https://www.google.com/maps/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('hotels_info.txt'):\n",
    "    hotels_df = pd.read_csv('hotels_info.txt', sep=',')\n",
    "    print(hotels_df.head())\n",
    "    unique_cities = hotels_df['City'].unique()\n",
    "    print(unique_cities)\n",
    "    unique_cities_df = pd.DataFrame(unique_cities, columns=['City'])\n",
    "    unique_cities_df.to_csv('unique_cities.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
